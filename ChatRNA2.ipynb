{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phodmin/CodonConcierge/blob/main/ChatRNA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The control panel\n",
        "setup_colab_environment()\n",
        "run_util3()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "TDVhp200FCym",
        "outputId": "6fdfc720-515f-4473-85e7-5a8e2d621505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2c6a994194cf>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# The control panel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msetup_colab_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'setup_colab_environment' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80aZ9t-kAk7q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "src_vocab_size = 22 # Amino acids (20 + '*' fors stop + 'X')\n",
        "tgt_vocab_size = 65 # Codons (64 + 1 'X' for padded, i.e. unknown codons)\n",
        "\n",
        "# Model Configurations\n",
        "MODEL_CONFIGS = {\n",
        "    \"small\": {\"d_model\": 128, \"num_heads\": 4, \"num_layers\": 2, \"d_ff\": 512, \"dropout\": 0.1},\n",
        "    \"medium\": {\"d_model\": 256, \"num_heads\": 8, \"num_layers\": 4, \"d_ff\": 1024, \"dropout\": 0.1},\n",
        "    \"large\": {\"d_model\": 512, \"num_heads\": 8, \"num_layers\": 6, \"d_ff\": 2048, \"dropout\": 0.1},\n",
        "    \"wide\": {\"d_model\": 1024, \"num_heads\": 16, \"num_layers\": 2, \"d_ff\": 4096, \"dropout\": 0.1},\n",
        "    \"shallow_multihead\": {\"d_model\": 256, \"num_heads\": 16, \"num_layers\": 2, \"d_ff\": 1024, \"dropout\": 0.1},\n",
        "    \"deep_narrow\": {\"d_model\": 128, \"num_heads\": 4, \"num_layers\": 10, \"d_ff\": 512, \"dropout\": 0.1}\n",
        "}\n",
        "\n",
        "DIFFUSION_CONFIGS = {\n",
        "    \"small\": {\"hidden_units\": 128, \"num_layers\": 2, \"dropout\": 0.1, \"num_diffusion_steps\": 50},\n",
        "    \"diffusion_medium\": {\"hidden_units\": 256, \"num_layers\": 4, \"dropout\": 0.1, \"num_diffusion_steps\": 100},\n",
        "    \"diffusion_extended_steps\": {\"hidden_units\": 256, \"num_layers\": 4, \"dropout\": 0.1, \"num_diffusion_steps\": 200},\n",
        "    \"diffusion_deep\": {\"hidden_units\": 128, \"num_layers\": 8, \"dropout\": 0.1, \"num_diffusion_steps\": 100},\n",
        "}\n",
        "\n",
        "def setup_colab_environment():\n",
        "    # File Path\n",
        "    gencode_source_file_path = './data/gencode/gencode.v44.pc_transcripts.fa'\n",
        "\n",
        "    # Check if the data file exists\n",
        "    if not os.path.exists(gencode_source_file_path):\n",
        "        # Create a directory if it doesn't exist\n",
        "        subprocess.run(\"mkdir -p data/gencode\", shell=True)\n",
        "\n",
        "        # Download the file\n",
        "        subprocess.run(\"wget -O data/gencode/gencode.v44.pc_transcripts.fa.gz https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_44/gencode.v44.pc_transcripts.fa.gz\", shell=True)\n",
        "\n",
        "        # Decompress the downloaded file\n",
        "        subprocess.run(\"gunzip data/gencode/gencode.v44.pc_transcripts.fa.gz\", shell=True)\n",
        "\n",
        "    # Check if Bio and tensorboardX are installed\n",
        "    try:\n",
        "        import Bio\n",
        "        import tensorboardX\n",
        "    except ImportError:\n",
        "        # Install required Python packages\n",
        "        subprocess.run(\"pip install Bio\", shell=True)\n",
        "        subprocess.run(\"pip install tensorboardX\", shell=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDeSsyB3tqGV"
      },
      "outputs": [],
      "source": [
        "def run_util3():\n",
        "    # @util3.py\n",
        "    import os\n",
        "    from Bio import SeqIO\n",
        "    from Bio.Seq import Seq\n",
        "    import pandas as pd\n",
        "    from io import StringIO\n",
        "    from typing import Tuple, List\n",
        "    from itertools import compress\n",
        "    from torch.nn.utils.rnn import pad_sequence\n",
        "    import pytest\n",
        "\n",
        "    # Define bases\n",
        "    bases = ['A', 'T', 'G', 'C', 'N']\n",
        "\n",
        "    def print_success(message):\n",
        "        # ANSI color codes\n",
        "        GREEN = \"\\033[92m\"\n",
        "        BOLD = \"\\033[1m\"\n",
        "        RESET = \"\\033[0m\"\n",
        "\n",
        "        # Emoji and styled message\n",
        "        success_emoji = \"âœ…\"\n",
        "        styled_message = f\"{GREEN}{BOLD}{success_emoji} {message} {success_emoji}{RESET}\"\n",
        "\n",
        "        # Border\n",
        "        border_length = len(message) + 4 + 4  # 4 for spaces & emoji, 4 for bold ANSI code characters\n",
        "        border = \"+\" + \"-\" * border_length + \"+\"\n",
        "\n",
        "        # Print the styled output\n",
        "        print(border)\n",
        "        print(f\"| {styled_message} |\")\n",
        "        print(border)\n",
        "\n",
        "    # Mapping codons to amino acids, standard capitalised IUPAC codes\n",
        "    # Padded codons (any that include N) are mapped to 'X'\n",
        "    codon_to_aa = {\n",
        "        'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M',\n",
        "        'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
        "        'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K',\n",
        "        'AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',\n",
        "        'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n",
        "        'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
        "        'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q',\n",
        "        'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
        "        'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',\n",
        "        'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
        "        'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E',\n",
        "        'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
        "        'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n",
        "        'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L',\n",
        "        'TAC':'Y', 'TAT':'Y', 'TAA':'*', 'TAG':'*',\n",
        "        'TGC':'C', 'TGT':'C', 'TGA':'*', 'TGG':'W',\n",
        "        # Adding the padded codons\n",
        "        'ANN':'X', 'CNN':'X', 'GNN':'X', 'TNN':'X',\n",
        "        'AAN':'X', 'CAN':'X', 'GAN':'X', 'TAN':'X',\n",
        "        'ANA':'X', 'CNA':'X', 'GNA':'X', 'TNA':'X',\n",
        "        'ANC':'X', 'CNC':'X', 'GNC':'X', 'TNC':'X',\n",
        "        'ANG':'X', 'CNG':'X', 'GNG':'X', 'TNG':'X',\n",
        "        'ANT':'X', 'CNT':'X', 'GNT':'X', 'TNT':'X',\n",
        "        'AGN':'X', 'CGN':'X', 'GGN':'X', 'TGN':'X',\n",
        "        'ATN':'X', 'CTN':'X', 'GTN':'X', 'TTN':'X',\n",
        "        'ACN':'X', 'CCN':'X', 'GCN':'X', 'TCN':'X',\n",
        "        'NAA':'X', 'NAC':'X', 'NAG':'X', 'NAT':'X',\n",
        "        'NCA':'X', 'NCC':'X', 'NCG':'X', 'NCT':'X',\n",
        "        'NGA':'X', 'NGC':'X', 'NGG':'X', 'NGT':'X',\n",
        "        'NTA':'X', 'NTC':'X', 'NTG':'X', 'NTT':'X',\n",
        "        'NAN':'X', 'NCN':'X', 'NGN':'X', 'NTN':'X',\n",
        "        'NNN':'X'\n",
        "    }\n",
        "\n",
        "    # Mapping amino acids to integers, 1-20\n",
        "    # Unknown Amino Acid ('X') is mapped to '0'\n",
        "    # Stop codon ('*') is mapped to '21'\n",
        "    aa_to_int = {\n",
        "        'A': 1, 'C': 2, 'D': 3, 'E': 4,\n",
        "        'F': 5, 'G': 6, 'H': 7, 'I': 8,\n",
        "        'K': 9, 'L':10, 'M':11, 'N':12,\n",
        "        'P':13, 'Q':14, 'R':15, 'S':16,\n",
        "        'T':17, 'V':18, 'W':19, 'Y':20,\n",
        "        # Unknown amino acid ('X') and stop codon ('*')\n",
        "        'X': 0, '*':21\n",
        "    }\n",
        "\n",
        "    # Mapping codons to ints, 1-64\n",
        "    # Padded codons (any that include N) are mapped to '0'\n",
        "    codon_to_int = {\n",
        "        'ATA': 1, 'ATC': 2, 'ATT': 3, 'ATG': 4,\n",
        "        'ACA': 5, 'ACC': 6, 'ACG': 7, 'ACT': 8,\n",
        "        'AAT': 9, 'AAC':10, 'AAA':11, 'AAG':12,\n",
        "        'AGA':13, 'AGC':14, 'AGG':15, 'AGT':16,\n",
        "        'CTA':17, 'CTC':18, 'CTT':19, 'CTG':20,\n",
        "        'CCA':21, 'CCC':22, 'CCG':23, 'CCT':24,\n",
        "        'CAT':25, 'CAC':26, 'CAA':27, 'CAG':28,\n",
        "        'CGA':29, 'CGC':30, 'CGG':31, 'CGT':32,\n",
        "        'GTA':33, 'GTC':34, 'GTT':35, 'GTG':36,\n",
        "        'GCA':37, 'GCC':38, 'GCG':39, 'GCT':40,\n",
        "        'GAT':41, 'GAC':42, 'GAA':43, 'GAG':44,\n",
        "        'GGA':45, 'GGC':46, 'GGG':47, 'GGT':48,\n",
        "        'TCA':49, 'TCC':50, 'TCT':51, 'TCG':52,\n",
        "        'TTA':53, 'TTC':54, 'TTT':55, 'TTG':56,\n",
        "        'TAT':57, 'TAC':58, 'TAA':59, 'TAG':60,\n",
        "        'TGA':61, 'TGC':62, 'TGG':63, 'TGT':64,\n",
        "        # Adding the padded codons\n",
        "        'ANN':0, 'CNN':0, 'GNN':0, 'TNN':0,\n",
        "        'AAN':0, 'CAN':0, 'GAN':0, 'TAN':0,\n",
        "        'ANA':0, 'CNA':0, 'GNA':0, 'TNA':0,\n",
        "        'ANC':0, 'CNC':0, 'GNC':0, 'TNC':0,\n",
        "        'ANG':0, 'CNG':0, 'GNG':0, 'TNG':0,\n",
        "        'ANT':0, 'CNT':0, 'GNT':0, 'TNT':0,\n",
        "        'AGN':0, 'CGN':0, 'GGN':0, 'TGN':0,\n",
        "        'ATN':0, 'CTN':0, 'GTN':0, 'TTN':0,\n",
        "        'ACN':0, 'CCN':0, 'GCN':0, 'TCN':0,\n",
        "        'NAA':0, 'NAC':0, 'NAG':0, 'NAT':0,\n",
        "        'NCA':0, 'NCC':0, 'NCG':0, 'NCT':0,\n",
        "        'NGA':0, 'NGC':0, 'NGG':0, 'NGT':0,\n",
        "        'NTA':0, 'NTC':0, 'NTG':0, 'NTT':0,\n",
        "        'NAN':0, 'NCN':0, 'NGN':0, 'NTN':0,\n",
        "        'NNN':0\n",
        "    }\n",
        "\n",
        "\n",
        "    # 0\n",
        "    def load_src_tgt_sequences(source_file: str, max_seq_length: int = 120000) -> Tuple[List[List[int]], List[List[int]]]:\n",
        "        \"\"\"\n",
        "        Load source and target sequences from a FASTA file and encode them into numerical sequences.\n",
        "\n",
        "        Args:\n",
        "            source_file (str): Path to the source FASTA file.\n",
        "            max_seq_length (int): Maximum length of the target sequences in nucleotides.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of two numpy arrays:\n",
        "            - aa_enc: Encoded amino acid sequences.\n",
        "            - codon_enc: Encoded codon sequences.\n",
        "        \"\"\"\n",
        "        # Input validation\n",
        "        if not os.path.exists(source_file):\n",
        "            raise FileNotFoundError(f\"Source file {source_file} not found\")\n",
        "\n",
        "        df = parse_fasta(source_file)\n",
        "\n",
        "        # Data extraction\n",
        "        df = extract_cds_columns(df)\n",
        "        aa_seqs, codon_seqs = extract_sequences(df)\n",
        "\n",
        "        # Filter sequences based on max_seq_length\n",
        "        valid_seq_mask = [(len(seq) * 3 <= max_seq_length) for seq in codon_seqs]\n",
        "        aa_seqs = list(compress(aa_seqs, valid_seq_mask))\n",
        "        codon_seqs = list(compress(codon_seqs, valid_seq_mask))\n",
        "\n",
        "        # Sequence encoding\n",
        "        aa_enc = encode_amino_sequence(aa_seqs)\n",
        "        codon_enc = encode_codon_sequence(codon_seqs)\n",
        "\n",
        "        return aa_enc, codon_enc\n",
        "\n",
        "    # 1\n",
        "    def parse_fasta(fasta_file):\n",
        "        records = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
        "        parsed_records = []\n",
        "        for record in records:\n",
        "            header_parts = record.description.split(\"|\")\n",
        "            transcript_info = {\n",
        "                \"transcript_id\": header_parts[0],\n",
        "                \"gene_id\": header_parts[1],\n",
        "                \"manual_gene_id\": header_parts[2],\n",
        "                \"manual_transcript_id\": header_parts[3],\n",
        "                \"gene_symbol_variant\": header_parts[4],\n",
        "                \"gene_name\": header_parts[5],\n",
        "                \"sequence_length\": int(header_parts[6]),\n",
        "                \"UTR5\": header_parts[7].split(\":\")[1] if len(header_parts) > 7 and \"UTR5\" in header_parts[7] else None,\n",
        "                \"CDS\": header_parts[8].split(\":\")[1] if len(header_parts) > 8 and \"CDS\" in header_parts[8] else None,\n",
        "                \"UTR3\": header_parts[9].split(\":\")[1] if len(header_parts) > 9 and \"UTR3\" in header_parts[9] else None,\n",
        "\n",
        "                \"sequence\": str(record.seq)\n",
        "            }\n",
        "            parsed_records.append(transcript_info)\n",
        "\n",
        "        df = pd.DataFrame(parsed_records)\n",
        "        return df\n",
        "\n",
        "    # 2\n",
        "    def extract_cds_columns(df):\n",
        "        \"\"\"Extract CDS start/end columns\"\"\"\n",
        "\n",
        "        # Split the 'CDS' column once\n",
        "        cds_splits = df['CDS'].str.split('-')\n",
        "\n",
        "        # Check if all rows have exactly two parts after splitting\n",
        "        valid_format = cds_splits.apply(lambda x: len(x) == 2 if x else False)\n",
        "\n",
        "        # For rows with the valid 'start-end' format\n",
        "        df.loc[valid_format, 'cds_start'] = cds_splits[valid_format].str[0].astype(int)\n",
        "        df.loc[valid_format, 'cds_end'] = cds_splits[valid_format].str[1].astype(int)\n",
        "\n",
        "        # For rows without the valid 'start-end' format or if 'CDS' is not found\n",
        "        default_indices = ~valid_format | df['CDS'].isna()\n",
        "        df.loc[default_indices, 'cds_start'] = 1\n",
        "        df.loc[default_indices, 'cds_end'] = df.loc[default_indices, 'sequence'].str.len()\n",
        "\n",
        "        # Ensure 'cds_start' and 'cds_end' are integers\n",
        "        df['cds_start'] = df['cds_start'].astype(int)\n",
        "        df['cds_end'] = df['cds_end'].astype(int)\n",
        "\n",
        "        valid_rows = (df['cds_start'] > 0) & (df['cds_end'] <= df['sequence'].str.len())\n",
        "        valid_df = df[valid_rows]\n",
        "        return valid_df\n",
        "\n",
        "    # 3\n",
        "\n",
        "    # 3.1 Codons -> amino acids\n",
        "    def translate_codons_to_amino_acids(codon_seqs: List[str]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Translate a list of codon sequences to their corresponding amino acid sequences.\n",
        "\n",
        "        If the codon sequence length isn't a multiple of 3, it will be padded with 'N'\n",
        "        to the nearest multiple of 3.\n",
        "\n",
        "        Parameters:\n",
        "        - codon_seqs (List[str]): A list of codon sequences.\n",
        "                                  Each codon is expected to be a triplet of nucleotide bases.\n",
        "\n",
        "        Returns:\n",
        "        - List[str]: A list of amino acid sequences corresponding to the input codon sequences.\n",
        "\n",
        "        Raises:\n",
        "        - ValueError: If a provided codon is not recognized.\n",
        "        \"\"\"\n",
        "\n",
        "        result = []\n",
        "\n",
        "        for seq in codon_seqs:\n",
        "            # Pad with 'N' if not multiple of 3\n",
        "            while len(seq) % 3 != 0:\n",
        "                seq += 'N'\n",
        "\n",
        "            amino_acid_seq = \"\"\n",
        "            for i in range(0, len(seq), 3):\n",
        "                codon = seq[i:i+3]\n",
        "                if codon not in codon_to_aa:\n",
        "                    raise ValueError(f\"Unrecognized codon: {codon}\")\n",
        "                amino_acid_seq += codon_to_aa[codon]\n",
        "\n",
        "            result.append(amino_acid_seq)\n",
        "\n",
        "        return result\n",
        "\n",
        "    # 3.2 Amino acids -> ints\n",
        "    def translate_amino_acids_to_ints(aa_seqs: List[str]) -> List[List[int]]:\n",
        "        \"\"\"\n",
        "        Translate a list of amino acid sequences to their corresponding integer sequences.\n",
        "\n",
        "        Parameters:\n",
        "        - aa_seqs (List[str]): A list of amino acid sequences.\n",
        "                              Each amino acid is represented as a single character.\n",
        "\n",
        "        Returns:\n",
        "        - List[List[int]]: A list of integer sequences corresponding to the input amino acid sequences.\n",
        "\n",
        "        Raises:\n",
        "        - ValueError: If a provided amino acid is not recognized.\n",
        "        \"\"\"\n",
        "\n",
        "        result = []\n",
        "\n",
        "        for seq in aa_seqs:\n",
        "            int_seq = []\n",
        "            for aa in seq:\n",
        "                if aa not in aa_to_int:\n",
        "                    raise ValueError(f\"Unrecognized amino acid: {aa}\")\n",
        "                int_seq.append(aa_to_int[aa])\n",
        "\n",
        "            result.append(int_seq)\n",
        "\n",
        "        return result\n",
        "\n",
        "    # 3.3 Codons -> ints\n",
        "    def translate_codons_to_ints(codon_seqs: List[str]) -> List[int]:\n",
        "        \"\"\"\n",
        "        Translate a list of codon sequences to their corresponding integer values.\n",
        "\n",
        "        If the codon sequence length isn't a multiple of 3, it will be padded with 'N'\n",
        "        to the nearest multiple of 3.\n",
        "\n",
        "        Parameters:\n",
        "        - codon_seqs (List[str]): A list of codon sequences.\n",
        "                                  Each codon is expected to be a triplet of nucleotide bases.\n",
        "\n",
        "        Returns:\n",
        "        - List[int]: A list of integer values corresponding to the input codon sequences.\n",
        "\n",
        "        Raises:\n",
        "        - ValueError: If a provided codon is not recognized.\n",
        "        \"\"\"\n",
        "\n",
        "        result = []\n",
        "\n",
        "        for seq in codon_seqs:\n",
        "            # Pad with 'N' if not multiple of 3\n",
        "            while len(seq) % 3 != 0:\n",
        "                seq += 'N'\n",
        "\n",
        "            int_values = []\n",
        "            for i in range(0, len(seq), 3):\n",
        "                codon = seq[i:i+3]\n",
        "                if codon not in codon_to_int:\n",
        "                    raise ValueError(f\"Unrecognized codon: {codon}\")\n",
        "                int_values.append(codon_to_int[codon])\n",
        "\n",
        "            result.append(int_values)\n",
        "\n",
        "        return result\n",
        "\n",
        "    # 4\n",
        "    def extract_sequences(df) -> Tuple[List[List[int]], List[List[int]]]:\n",
        "        \"\"\"\n",
        "        Extracts amino acid and codon sequences from the 'sequence' field in the DataFrame.\n",
        "\n",
        "        Args:\n",
        "            df: A pandas DataFrame containing the 'sequence', 'cds_start', and 'cds_end' columns.\n",
        "\n",
        "        Returns:\n",
        "            A tuple containing two lists:\n",
        "            - aa_seqs_int: A list of amino acid sequences as integers.\n",
        "            - codon_seqs_int: A list of codon sequences as integers.\n",
        "        \"\"\"\n",
        "\n",
        "        aa_seqs_int = []   # For storing amino acid sequences as integers\n",
        "        codon_seqs_int = []   # For storing codon sequences as integers\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row['sequence'][row['cds_start']-1:row['cds_end']]  # -1 because Python is 0-based\n",
        "\n",
        "            # Extracting codons\n",
        "            codons = [seq[i:i+3] for i in range(0, len(seq), 3) if 1 <= len(seq[i:i+3]) <= 3]\n",
        "\n",
        "            # Getting the amino acid integer sequences\n",
        "            aa_seqs = translate_codons_to_amino_acids(codons)\n",
        "            aa_ints = [aa for seq in translate_amino_acids_to_ints(aa_seqs) for aa in seq]\n",
        "\n",
        "            # Getting the codon integer sequences\n",
        "            codon_ints = [codon for seq in translate_codons_to_ints(codons) for codon in seq]\n",
        "\n",
        "            codon_seqs_int.append(codon_ints)\n",
        "            aa_seqs_int.append(aa_ints)\n",
        "\n",
        "        return aa_seqs_int, codon_seqs_int\n",
        "\n",
        "\n",
        "    # 5 Dummy encode functions\n",
        "    def encode_amino_sequence(aa_seqs: List[List[int]]) -> List[List[int]]:\n",
        "        return aa_seqs\n",
        "\n",
        "    def encode_codon_sequence(codon_seqs: List[List[int]]) -> List[List[int]]:\n",
        "        return codon_seqs\n",
        "\n",
        "    # 6\n",
        "    def collate_fn(batch):\n",
        "        src_sequences, tgt_sequences = zip(*batch)\n",
        "        # Padding sequences\n",
        "        src_sequences = pad_sequence(src_sequences, batch_first=True)\n",
        "        tgt_sequences = pad_sequence(tgt_sequences, batch_first=True)\n",
        "        return src_sequences, tgt_sequences\n",
        "\n",
        "    # 7\n",
        "\n",
        "    # 7.1 Ints -> Amino acids\n",
        "    def translate_ints_to_amino_acids(int_seqs: List[List[int]]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Translate a list of integer sequences to their corresponding amino acid sequences.\n",
        "\n",
        "        Parameters:\n",
        "        - int_seqs (List[List[int]]): A list of integer sequences representing amino acids.\n",
        "\n",
        "        Returns:\n",
        "        - List[str]: A list of amino acid sequences corresponding to the input integer sequences.\n",
        "\n",
        "        Raises:\n",
        "        - ValueError: If a provided integer is not recognized.\n",
        "        \"\"\"\n",
        "        int_to_aa = {v: k for k, v in aa_to_int.items()}\n",
        "\n",
        "        result = []\n",
        "        for seq in int_seqs:\n",
        "            aa_seq = \"\"\n",
        "            for i in seq:\n",
        "                if i not in int_to_aa:\n",
        "                    raise ValueError(f\"Unrecognized integer: {i}\")\n",
        "                aa_seq += int_to_aa[i]\n",
        "            result.append(aa_seq)\n",
        "        return result\n",
        "\n",
        "    # 7.2 Ints -> Codons\n",
        "    def translate_ints_to_codons(int_seqs: List[List[int]]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Translate a list of integer sequences to their corresponding codon sequences.\n",
        "\n",
        "        Parameters:\n",
        "        - int_seqs (List[List[int]]): A list of integer sequences representing codons.\n",
        "\n",
        "        Returns:\n",
        "        - List[str]: A list of codon sequences corresponding to the input integer sequences.\n",
        "\n",
        "        Raises:\n",
        "        - ValueError: If a provided integer is not recognized.\n",
        "        \"\"\"\n",
        "        int_to_codon = {v: k for k, v in codon_to_int.items()}\n",
        "\n",
        "        result = []\n",
        "        for seq in int_seqs:\n",
        "            codon_seq = \"\"\n",
        "            for i in seq:\n",
        "                if i not in int_to_codon:\n",
        "                    raise ValueError(f\"Unrecognized integer: {i}\")\n",
        "                codon_seq += int_to_codon[i]\n",
        "            result.append(codon_seq)\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqwyqRlRowLg"
      },
      "source": [
        "# codonFormer.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE4Kvdgs0cNx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "import time\n",
        "from datetime import datetime\n",
        "from tensorboardX import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from util import *\n",
        "#from util3 import *\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_length):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def generate_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
        "        seq_length = tgt.size(1)\n",
        "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
        "\n",
        "        # GPU Specific\n",
        "        # Ensure the nopeak_mask is on the same device as tgt_mask\n",
        "        nopeak_mask = nopeak_mask.to(tgt_mask.device)\n",
        "\n",
        "        tgt_mask = tgt_mask & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        output = self.fc(dec_output)\n",
        "        return output\n",
        "\n",
        "class SequenceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, src_sequences, tgt_sequences):\n",
        "        assert len(src_sequences) == len(tgt_sequences), \"Source and target sequences must have the same length.\"\n",
        "        self.src_sequences = src_sequences\n",
        "        self.tgt_sequences = tgt_sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        src_sequence = encode_amino_sequence(self.src_sequences[index])\n",
        "\n",
        "        tgt_sequence = encode_codon_sequence(self.tgt_sequences[index])\n",
        "        return torch.tensor(src_sequence), torch.tensor(tgt_sequence)\n",
        "\n",
        "def get_gpu_memory_usage(device):\n",
        "    return torch.cuda.memory_allocated(device) / 1e6  # Convert bytes to MB\n",
        "\n",
        "def train_model(model, dataloader, val_dataloader, tgt_vocab_size, epochs=100, lr=0.0001, verbose=False, start_epoch=0, optimizer_state_dict=None):\n",
        "    current_memory_usage = 0\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # 0 is used for padding.\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "    # Load optimizer state if provided\n",
        "    if optimizer_state_dict:\n",
        "        optimizer.load_state_dict(optimizer_state_dict)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):  # Adjusted loop range\n",
        "        if verbose:\n",
        "            start_time = time.time()\n",
        "            current_memory_usage = get_gpu_memory_usage(device)  # Assuming `device` is defined and passed to the function\n",
        "\n",
        "        for batch_idx, (src_data, tgt_data) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            src_data, tgt_data = src_data.to(device), tgt_data.to(device)\n",
        "            output = model(src_data, tgt_data[:, :-1])\n",
        "            loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
        "            loss.backward()\n",
        "\n",
        "            if verbose:\n",
        "                grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "        # Computing the Validation Loss every 5th epoch\n",
        "        if verbose and (epoch + 1) % 5 == 0:\n",
        "            val_loss = validate(model, val_dataloader, criterion, tgt_vocab_size)\n",
        "            end_time = time.time()\n",
        "            current_memory_usage = torch.cuda.memory_allocated(device) / 1e6  # in MBs\n",
        "            print(f\"\\033[1;44mEpoch: {epoch+1}, Training Loss: {loss.item()}, Validation Loss: {val_loss}\\033[0m\")\n",
        "            print(f\"\\tTime taken for Epoch {epoch+1}: {end_time - start_time:.2f} seconds\")\n",
        "            print(f\"\\tGradient Norm: {grad_norm:.2f}\")\n",
        "            if 'current_memory_usage' in locals():\n",
        "                print(f\"\\tMemory Usage: {current_memory_usage:.2f} MBs\")\n",
        "        elif verbose:\n",
        "            # Print without validation loss\n",
        "            end_time = time.time()\n",
        "            print(f\"\\033[1mEpoch: {epoch+1}, Training Loss: {loss.item()}\\033[0m\")\n",
        "            print(f\"\\tTime taken for Epoch {epoch+1}: {end_time - start_time:.2f} seconds\")\n",
        "            print(f\"\\tGradient Norm: {grad_norm:.2f}\")\n",
        "            if 'current_memory_usage' in locals():\n",
        "                print(f\"\\tMemory Usage: {current_memory_usage:.2f} MBs\")\n",
        "\n",
        "def validate(model, dataloader, criterion, tgt_vocab_size):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (src_data, tgt_data) in enumerate(dataloader):\n",
        "            src_data, tgt_data = src_data.to(device), tgt_data.to(device)\n",
        "            output = model(src_data, tgt_data[:, :-1])\n",
        "            loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
        "            total_loss += loss.item()\n",
        "    model.train()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# def predict(model, src_sequence):\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         src_sequence = torch.tensor(encode_amino_sequence(src_sequence)).unsqueeze(0) # assuming the encoding function is available\n",
        "#         tgt_start_token = torch.tensor([SOME_START_TOKEN_INDEX])  # You'll need a start token for decoding\n",
        "#         output = model(src_sequence, tgt_start_token)\n",
        "#         predicted = output.argmax(dim=-1)\n",
        "#         return decode_codon_sequence(predicted[0]) # assuming a decoding function is available\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "def initialise_training(max_seq_length=2000, config=\"large\", batch=64, n_epochs=100, gencode_source_file_path=None):\n",
        "    \"\"\"\n",
        "    Initialise the training process.\n",
        "\n",
        "    Parameters:\n",
        "    - max_seq_length (int): Longest allowable sequence\n",
        "    - config (str): Model configuration\n",
        "    - batch (int): Batch size\n",
        "    - n_epochs (int): Number of epochs\n",
        "    - gencode_source_file_path (str): Path to the source file\n",
        "\n",
        "    Returns:\n",
        "    - train_dataloader, val_dataloader, transformer, device\n",
        "    \"\"\"\n",
        "    print_success(\"Done setting the constants.\")\n",
        "\n",
        "    # Define, set, and check the device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # Get current date and time\n",
        "    current_time = datetime.now()\n",
        "    timestamp = current_time.strftime('%Y/%m/%d_%H:%M:%S')\n",
        "    run_name = \"saturday_big_model\"\n",
        "    writer = SummaryWriter('runs/' + run_name)\n",
        "\n",
        "    src_sequences, tgt_sequences = load_src_tgt_sequences(source_file=gencode_source_file_path, max_seq_length=max_seq_length)\n",
        "    src_train, src_val, tgt_train, tgt_val = train_test_split(src_sequences, tgt_sequences, test_size=0.1)\n",
        "\n",
        "    print(\"Done loading the data.\")\n",
        "\n",
        "    # Filtering training and validation data\n",
        "    filtered_train_data = [(src, tgt) for src, tgt in zip(src_train, tgt_train) if len(src) <= max_seq_length]\n",
        "    filtered_val_data = [(src, tgt) for src, tgt in zip(src_val, tgt_val) if len(src) <= max_seq_length]\n",
        "    print(f\"Filtered from {len(src_train)} to {len(filtered_train_data)} training sequences.\")\n",
        "    print(f\"Filtered from {len(src_val)} to {len(filtered_val_data)} validation sequences.\")\n",
        "    src_train, tgt_train = zip(*filtered_train_data)\n",
        "    src_val, tgt_val = zip(*filtered_val_data)\n",
        "\n",
        "    # Create training and validation datasets and dataloaders\n",
        "    train_dataset = SequenceDataset(src_train, tgt_train)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=True, collate_fn=collate_fn)\n",
        "    print(\"Done creating the training dataloader.\")\n",
        "\n",
        "    val_dataset = SequenceDataset(src_val, tgt_val)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch, shuffle=False, collate_fn=collate_fn)\n",
        "    print(\"Done creating the validation dataloader.\")\n",
        "\n",
        "    config_params = MODEL_CONFIGS[config]\n",
        "    print(f\"Done setting - Model Configuration: {config_params}\")\n",
        "    transformer = Transformer(src_vocab_size, tgt_vocab_size, **config_params, max_seq_length=max_seq_length)\n",
        "\n",
        "    transformer = transformer.to(device)\n",
        "    print(\"Model loaded to the device (GPU).\")\n",
        "\n",
        "    return train_dataloader, val_dataloader, transformer, device\n"
      ],
      "metadata": {
        "id": "GPIGsF9EvuZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfW_89pWGl81"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    max_seq_length = 200 # Longest allowable sequence\n",
        "    config = \"large\" # Hyperparameters\n",
        "    batch = 256 # Size: 64, 128, 256, 512, 1024, 2048\n",
        "    # (A100 runs out of memory at 2048 + medium config)\n",
        "    # (A100 cannot do max_seq_length = 2000 & large at more than 64 batch size)\n",
        "    n_epochs = 100 # Choose num of epochs\n",
        "\n",
        "    print_success(\"Done setting the constants.\")\n",
        "\n",
        "    # Define, set, and check the device\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device: \" + str(device))\n",
        "\n",
        "    # Get the current date and time\n",
        "    current_time = datetime.now()\n",
        "\n",
        "    # Format the timestamp as year_month_day_hour_minute_second\n",
        "    timestamp = current_time.strftime('%Y/%m/%d_%H:%M:%S')\n",
        "\n",
        "    # Initialize a name for the training run\n",
        "    #run_name = timestamp + \"_LengthCap-\" + str(max_seq_length) + \"_HPsize-\" + config + \"_Batch-\" + str(batch)\n",
        "    run_name = \"saturday_big_model\"\n",
        "    # Initialize a writer\n",
        "    writer = SummaryWriter('runs/' + run_name)\n",
        "\n",
        "    # After training, navigate to the parent directory of 'runs' in the terminal.\n",
        "    # Start TensorBoard by running the following command:\n",
        "    # tensorboard --logdir=runs\n",
        "    #\n",
        "    # Then, open a web browser and navigate to the URL displayed in the terminal (usually http://localhost:6006/).\n",
        "    # You should be able to see your logs and navigate between different experiments using the unique names.\n",
        "\n",
        "    #src_sequences, tgt_sequences = load_src_tgt_sequences()\n",
        "    src_sequences, tgt_sequences = load_src_tgt_sequences(source_file=gencode_source_file_path,max_seq_length=max_seq_length)\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    src_train, src_val, tgt_train, tgt_val = train_test_split(src_sequences, tgt_sequences, test_size=0.1)\n",
        "\n",
        "    print(\"Done loading the data.\")\n",
        "\n",
        "    # Filtering the training data\n",
        "    filtered_train_data = [(src, tgt) for src, tgt in zip(src_train, tgt_train) if len(src) <= max_seq_length]\n",
        "    print(f\"Filtered from {len(src_train)} to {len(filtered_train_data)} training sequences.\")\n",
        "    src_train, tgt_train = zip(*filtered_train_data)\n",
        "\n",
        "    # Filtering the validation data\n",
        "    filtered_val_data = [(src, tgt) for src, tgt in zip(src_val, tgt_val) if len(src) <= max_seq_length]\n",
        "    print(f\"Filtered from {len(src_val)} to {len(filtered_val_data)} validation sequences.\")\n",
        "    src_val, tgt_val = zip(*filtered_val_data)\n",
        "\n",
        "    # Create training dataset and dataloader\n",
        "    train_dataset = SequenceDataset(src_train, tgt_train)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=True, collate_fn=collate_fn)\n",
        "    print(\"Done creating the training dataloader.\")\n",
        "\n",
        "    # Create validation dataset and dataloader\n",
        "    val_dataset = SequenceDataset(src_val, tgt_val)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch, shuffle=False, collate_fn=collate_fn)  # No need to shuffle the validation data\n",
        "    print(\"Done creating the validation dataloader.\")\n",
        "\n",
        "    # Create the transformer model using the chosen configuration\n",
        "    config_params = MODEL_CONFIGS[config]\n",
        "    print(f\"Done setting - Model Configuration: {config_params}\")\n",
        "    transformer = Transformer(src_vocab_size, tgt_vocab_size, **config_params, max_seq_length=max_seq_length)\n",
        "\n",
        "    # Move the model to GPU if available\n",
        "    transformer = transformer.to(device)\n",
        "    print(\"Model loaded to the device (GPU).\")\n",
        "\n",
        "    # Train the model\n",
        "    print_success(\"INITIALISE TRAINING.\")\n",
        "    train_model(transformer, train_dataloader, val_dataloader, tgt_vocab_size=tgt_vocab_size, epochs=n_epochs, verbose=True)\n",
        "\n",
        "    # Close the writer\n",
        "    writer.close()\n",
        "\n",
        "    # Report the number of params\n",
        "    num_params = sum(p.numel() for p in transformer.parameters())\n",
        "    print_success(f\"Training finished! The model has {num_params} parameters.\")\n",
        "\n",
        "    # Save the model to a file\n",
        "    save_path = 'model_' + run_name\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "\n",
        "    torch.save(transformer.state_dict(), os.path.join(save_path, 'my_model.pt'))\n",
        "    torch.save(transformer, os.path.join(save_path, 'my_model_complete.pt'))\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    import shutil\n",
        "\n",
        "    # Source paths\n",
        "    #src_path1 = '/content/runs/2023/09/14_02:19:50_LengthCap:500_HPsize:medium_Batch:1024'\n",
        "    #src_path2 = '/content/model_2023'\n",
        "    src_path1 = '/content/runs/saturday_big_model'\n",
        "    src_path2 = '/content/model_saturday_big_model'\n",
        "\n",
        "\n",
        "    # Destination paths\n",
        "    dst_path1 = '/content/gdrive/My Drive/Thesis/2023/09/14_02:19:50_LengthCap:500_HPsize:medium_Batch:1024'\n",
        "    dst_path2 = '/content/gdrive/My Drive/Thesis/model_2023'\n",
        "\n",
        "    # Copy the directories to the destination paths\n",
        "    shutil.copytree(src_path1, dst_path1)\n",
        "    shutil.copytree(src_path2, dst_path2)\n"
      ],
      "metadata": {
        "id": "ZTjt-dk2VvuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training output"
      ],
      "metadata": {
        "id": "y2aX2RaluKY1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylf0wC0YeAZF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "model_save_path = \"/content/model_checkpoint.pth\"\n",
        "#optimizer_save_path = \"/content/optimizer_checkpoint.pth\"\n",
        "\n",
        "torch.save({\n",
        "    'epoch': 47,  # current epoch number\n",
        "    'model_state_dict': transformer.state_dict(),\n",
        "    #'optimizer_state_dict': optimizer.state_dict(),  # assuming you named your optimizer 'optimizer'\n",
        "    'loss': 0.5647182464599609,  # you can save the latest loss value\n",
        "}, model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC3AGtBUMN4M"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Change 'MyDrive/checkpoints/' to your desired path within Google Drive\n",
        "model_save_path = \"/content/drive/MyDrive/checkpoints/model_checkpoint.pth\"\n",
        "import os\n",
        "save_directory = \"/content/drive/MyDrive/checkpoints/\"\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3aU0S7VMwqB"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "\n",
        "# First, save to Colab VM\n",
        "model_save_path = \"/content/model_checkpoint.pth\"\n",
        "torch.save({\n",
        "    'epoch': 47,\n",
        "    'model_state_dict': transformer.state_dict(),\n",
        "    #'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': 0.5647182464599609,\n",
        "}, model_save_path)\n",
        "\n",
        "# Then, download\n",
        "files.download(model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resume training"
      ],
      "metadata": {
        "id": "7zroQPzaV-kL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "def train_and_save_model(model, dataloader, val_dataloader, tgt_vocab_size, epochs=100, lr=0.0001, verbose=False, start_epoch=0, optimizer_state_dict=None, save_path=\"/content/\"):\n",
        "    def save_checkpoint(epoch, model, filename, optimizer= None):\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }, filename)\n",
        "\n",
        "    # Train the model\n",
        "    train_model(model, dataloader, val_dataloader, tgt_vocab_size, epochs, lr, verbose, start_epoch, optimizer_state_dict)\n",
        "\n",
        "    # Save after every epoch\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        filename = os.path.join(save_path, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
        "        save_checkpoint(epoch, model, filename)\n",
        "\n",
        "def initialize_or_load_checkpoint(model_path, model):\n",
        "    \"\"\"\n",
        "    Initializes or loads a checkpoint based on the presence of the specified model path.\n",
        "    Returns the model, optimizer state and starting epoch.\n",
        "    \"\"\"\n",
        "    start_epoch = 0\n",
        "    optimizer_state_dict = None\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        checkpoint = torch.load(model_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        if 'optimizer_state_dict' in checkpoint:\n",
        "            optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
        "        start_epoch = checkpoint['epoch'] + 1  # Start from the next epoch\n",
        "\n",
        "    return model, start_epoch, optimizer_state_dict\n",
        "\n",
        "train_dataloader, val_dataloader, transformer, device = initialise_training(gencode_source_file_path=gencode_source_file_path)\n",
        "\n",
        "# Initialize or load checkpoint\n",
        "model_path = \"/content/model_checkpoint.pth\"\n",
        "transformer, start_epoch, optimizer_state_dict = initialize_or_load_checkpoint(model_path, transformer)\n",
        "\n",
        "# Redefine number of epochs\n",
        "n_epochs = 100\n",
        "\n",
        "# Adjust the training call to pass optimizer state dict if available\n",
        "train_and_save_model(transformer, train_dataloader, val_dataloader, tgt_vocab_size=tgt_vocab_size, epochs=n_epochs, verbose=True, start_epoch=start_epoch, optimizer_state_dict=optimizer_state_dict)"
      ],
      "metadata": {
        "id": "qtbc0nx_TdOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdlmdt4Udvbb"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    max_seq_length = 200 # Longest allowable sequence\n",
        "    config = \"large\" # Hyperparameters\n",
        "    batch = 256 # Size: 64, 128, 256, 512, 1024, 2048 (A100 runs out of memory at 2048 + medium config)\n",
        "    n_epochs = 100 # Choose num of epochs\n",
        "\n",
        "    print_success(\"Done setting the constants.\")\n",
        "\n",
        "    # Define, set, and check the device\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device: \" + str(device))\n",
        "\n",
        "    # Get the current date and time\n",
        "    current_time = datetime.now()\n",
        "\n",
        "    # Format the timestamp as year_month_day_hour_minute_second\n",
        "    timestamp = current_time.strftime('%Y/%m/%d_%H:%M:%S')\n",
        "\n",
        "    # Initialize a name for the training run\n",
        "    #run_name = timestamp + \"_LengthCap-\" + str(max_seq_length) + \"_HPsize-\" + config + \"_Batch-\" + str(batch)\n",
        "    run_name = \"saturday_big_model\"\n",
        "    # Initialize a writer\n",
        "    writer = SummaryWriter('runs/' + run_name)\n",
        "    # Filtering the validation data\n",
        "    filtered_val_data = [(src, tgt) for src, tgt in zip(src_val, tgt_val) if len(src) <= max_seq_length]\n",
        "    print(f\"Filtered from {len(src_val)} to {len(filtered_val_data)} validation sequences.\")\n",
        "    src_val, tgt_val = zip(*filtered_val_data)\n",
        "\n",
        "    # Create training dataset and dataloader\n",
        "    train_dataset = SequenceDataset(src_train, tgt_train)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=True, collate_fn=collate_fn)\n",
        "    print(\"Done creating the training dataloader.\")\n",
        "\n",
        "    # Create validation dataset and dataloader\n",
        "    val_dataset = SequenceDataset(src_val, tgt_val)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch, shuffle=False, collate_fn=collate_fn)  # No need to shuffle the validation data\n",
        "    print(\"Done creating the validation dataloader.\")\n",
        "\n",
        "    # Create the transformer model using the chosen configuration\n",
        "    config_params = MODEL_CONFIGS[config]\n",
        "    print(f\"Done setting - Model Configuration: {config_params}\")\n",
        "    transformer = Transformer(src_vocab_size, tgt_vocab_size, **config_params, max_seq_length=max_seq_length)\n",
        "\n",
        "    # Move the model to GPU if available\n",
        "    transformer = transformer.to(device)\n",
        "    print(\"Model loaded to the device (GPU).\")\n",
        "\n",
        "    ##########     Train the model    ##########\n",
        "    print_success(\"INITIALISE TRAINING.\")\n",
        "    train_model(transformer, train_dataloader, val_dataloader, tgt_vocab_size=tgt_vocab_size, epochs=n_epochs, verbose=True)\n",
        "\n",
        "  ##########  ##########  ##########  ##########  ##########\n",
        "\n",
        "    # Close the writer\n",
        "    writer.close()\n",
        "\n",
        "    # Report the number of params\n",
        "    num_params = sum(p.numel() for p in transformer.parameters())\n",
        "    print_success(f\"Training finished! The model has {num_params} parameters.\")\n",
        "\n",
        "    # Save the model to a file\n",
        "    save_path = 'model_' + run_name\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "\n",
        "    torch.save(transformer.state_dict(), os.path.join(save_path, 'my_model.pt'))\n",
        "    torch.save(transformer, os.path.join(save_path, 'my_model_complete.pt'))\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    import shutil\n",
        "\n",
        "    # Source paths\n",
        "    #src_path1 = '/content/runs/2023/09/14_02:19:50_LengthCap:500_HPsize:medium_Batch:1024'\n",
        "    #src_path2 = '/content/model_2023'\n",
        "    src_path1 = '/content/runs/saturday_big_model'\n",
        "    src_path2 = '/content/model_saturday_big_model'\n",
        "\n",
        "\n",
        "    # Destination paths\n",
        "    dst_path1 = '/content/gdrive/My Drive/Thesis/2023/09/14_02:19:50_LengthCap:500_HPsize:medium_Batch:1024'\n",
        "    dst_path2 = '/content/gdrive/My Drive/Thesis/model_2023'\n",
        "\n",
        "    # Copy the directories to the destination paths\n",
        "    shutil.copytree(src_path1, dst_path1)\n",
        "    shutil.copytree(src_path2, dst_path2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPNiiWvQbNXi"
      },
      "source": [
        "# Infrastructure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl9QRWP2oe8k"
      },
      "outputs": [],
      "source": [
        "torch.save(transformer.state_dict(), 'model_checkpoint.pth')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cp model_checkpoint.pth '/content/gdrive/My Drive/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGoaODFpYtcA"
      },
      "outputs": [],
      "source": [
        "#del transformer\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EDU_88hzYsP"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "\n",
        "del transformer  # or any other variable\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU4WG4HAr0Uv"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/runs/2023/09/14_02:19:50_LengthCap:500_HPsize:medium_Batch:1024')  # replace 'path_to_file' with your file's path\n",
        "files.download('/content/model_2023')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCTKFe_xWDMD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBbmEmbiutEy"
      },
      "outputs": [],
      "source": [
        "\n",
        "import shutil\n",
        "\n",
        "# Source paths\n",
        "src_path1 = '/content/runs/2023/09/14_02:19:50_LengthCap:500_HPsize:medium_Batch:1024'\n",
        "src_path2 = '/content/model_2023'\n",
        "\n",
        "# Destination paths\n",
        "dst_path1 = '/content/gdrive/My Drive/Thesis/2023/09/14_02:19:50_LengthCap:500_HPsize:medium_Batch:1024'\n",
        "dst_path2 = '/content/gdrive/My Drive/Thesis/model_2023'\n",
        "\n",
        "# Copy the directories to the destination paths\n",
        "shutil.copytree(src_path1, dst_path1)\n",
        "shutil.copytree(src_path2, dst_path2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky8Jx9a6xnaD"
      },
      "source": [
        "# stableTranslation.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyqesKYwxhn7"
      },
      "outputs": [],
      "source": [
        "# @transformerCodonConcierge.py\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "mount_file_id": "1pv-PQlPJ5B3-mo3WsJO-l_fIuxuuLU97",
      "authorship_tag": "ABX9TyP0VKtjxoqhjXS0lGbfu9uO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}